<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CourtGuard: A Model-Agnostic Framework for Zero-Shot Policy Adaptation in LLM Safety</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.0/font/bootstrap-icons.css">
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <nav class="navbar navbar-expand-lg navbar-light bg-light sticky-top">
        <div class="container">
            <a class="navbar-brand fw-bold" href="#home">CourtGuard</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item"><a class="nav-link" href="#abstract">Abstract</a></li>
                    <li class="nav-item"><a class="nav-link" href="#problem">Adaptation Rigidity</a></li>
                    <li class="nav-item"><a class="nav-link" href="#framework">CourtGuard Framework</a></li>
                    <li class="nav-item"><a class="nav-link" href="#results">Results</a></li>
                    <li class="nav-item"><a class="nav-link" href="#findings">Key Findings</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <section id="home" class="hero-section py-5">
        <div class="container">
            <div class="row align-items-center">
                <div class="col-lg-12">
                    <h1 class="display-4 fw-bold text-primary mb-4 text-center">
                        CourtGuard: A Model-Agnostic Framework for <br> 
                        Zero-Shot Policy Adaptation in <br>
                        LLM Safety
                    </h1>
                    <p class="lead text-muted mb-4 text-center">
                        A retrieval-augmented multi-agent framework that reimagines safety evaluation as Evidentiary Debate. <br>
                        By orchestrating an adversarial debate grounded in external policy documents, it overcomes adaptation rigidity without expensive retraining.
                    </p>

                    <div class="text-center mb-4 d-flex justify-content-center gap-3 flex-wrap">
                        <a href="https://anonymous.4open.science/r/CourtGuard_ICML/README.md" class="btn btn-primary btn-lg">
                            <i class="bi bi-github"></i> Datasets & Code
                        </a>
                        <a href="https://anonymous.4open.science/r/CourtGuard_ICML/README.md" class="btn btn-outline-primary btn-lg">
                            <i class="bi bi-file-earmark-text"></i> Read Paper
                        </a>
                    </div>

                    <div class="authors-section text-center mb-4">
                        <h5 class="mb-2">Authors</h5>
                        <p class="authors-names mb-1">
                            <strong>Umid Suleymanov*, Rufiz Bayramov*, Suad Gafarli*, Seljan Musayeva, Taghi Mammadov, Aynur Akhundlu, Murat Kantarcioglu</strong>
                        </p>
                        <p class="text-muted small">Virginia Tech, ADA University</p>
                    </div>
                    
                    <div class="key-stats row">
                        <div class="col-md-4 mb-3">
                            <div class="stat-card text-center p-4 rounded shadow-sm border">
                                <h3 class="text-success">90%</h3>
                                <p class="mb-0 text-muted">Accuracy on Zero-Shot Wikipedia Vandalism</p>
                            </div>
                        </div>
                        <div class="col-md-4 mb-3">
                            <div class="stat-card text-center p-4 rounded shadow-sm border">
                                <h3 class="text-success">93.9%</h3>
                                <p class="mb-0 text-muted">Expert-AI Alignment in Legal Compliance</p>
                            </div>
                        </div>
                        <div class="col-md-4 mb-3">
                            <div class="stat-card text-center p-4 rounded shadow-sm border">
                                <h3 class="text-info">8</h3>
                                <p class="mb-0 text-muted">Safety Benchmarks Evaluated</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="abstract" class="py-5 bg-light">
        <div class="container">
            <h2 class="section-title">Abstract</h2>
            <div class="row">
                <div class="col-lg-10 mx-auto">
                    <div class="abstract-content p-4 bg-white rounded shadow-sm">
                        <p class="lead">
                            Current safety mechanisms for Large Language Models (LLMs) rely heavily on static, fine-tuned classifiers that suffer from <strong>adaptation rigidity</strong>, the inability to enforce new governance rules without expensive retraining.
                        </p>
                        <p>
                            To address this, we introduce <strong>COURTGUARD</strong>, a retrieval-augmented multi-agent framework that reimagines safety evaluation as Evidentiary Debate. By orchestrating an adversarial debate grounded in external policy documents, COURTGUARD achieves state-of-the-art performance across 7 safety benchmarks, outperforming dedicated policy-following baselines without fine-tuning.
                        </p>
                        <div class="research-questions mt-4">
                            <h5>Core Contributions</h5>
                            <ul class="rq-list">
                                <li><strong>Dynamic Policy Adaptability:</strong> Generalizes to out-of-domain tasks (Wikipedia Vandalism and Legal Domain adaptation based on GDPR) without fine-tuning, solely by swapping the reference policy.</li>
                                <li><strong>Evidentiary Debate:</strong> Replaces opaque model intuition with verifiable citations, mitigating hallucination risks by constraining agents to strictly ground arguments in retrieved clauses.</li>
                                <li><strong>Automated Data Curation & Auditing:</strong> Acts as a high-fidelity automated annotator to uncover label noise in existing benchmarks.</li>
                                <li><strong>Architectural Agnosticism:</strong> Compatible with diverse architectures (Llama-3-70B, GPT-OSS-20B), preventing vendor lock-in and allowing modular composition.</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="problem" class="py-5">
        <div class="container">
            <h2 class="section-title">The Problem: Adaptation Rigidity</h2>
            <p class="text-center mb-5">
                The landscape of LLM safety evaluation has evolved, but current defenses fall into rigid paradigms that fail when a deployment environment undergoes a sudden policy shift (e.g., a "Medical Advice Shift").
            </p>

            <div class="row">
                <div class="col-lg-4 mb-4">
                    <div class="semsi-category" data-category="static">
                        <div class="category-header" onclick="toggleCategory('static', event)">
                            <h4 class="icon-identity">Static Guardrails</h4>
                            <span class="toggle-icon">+</span>
                        </div>
                        <div class="category-content" id="static-content">
                            <p><strong>Definition:</strong> Models explicitly trained for safety classification and refusal (e.g., LlamaGuard, WildGuard, ShieldGemma).</p>
                            <div class="examples">
                                <h6>Limitations:</h6>
                                <ul>
                                    <li>Bakes safety alignments directly into weights.</li>
                                    <li>Suffers from the "alignment lag".</li>
                                    <li>Requires costly retraining to adapt to new rules.</li>
                                </ul>
                            </div>
                            <div class="threat-level">
                                <span class="badge bg-warning">Adaptation Risk</span>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="col-lg-4 mb-4">
                    <div class="semsi-category" data-category="agentic">
                        <div class="category-header" onclick="toggleCategory('agentic', event)">
                            <h4 class="icon-reputation">Agentic Adjudication</h4>
                            <span class="toggle-icon">+</span>
                        </div>
                        <div class="category-content" id="agentic-content">
                            <p><strong>Definition:</strong> LLM-as-a-Judge frameworks that use reasoning or multi-agent voting (e.g., JailJudge).</p>
                            <div class="examples">
                                <h6>Limitations:</h6>
                                <ul>
                                    <li>Relies on internal parametric knowledge.</li>
                                    <li><strong>Hallucination:</strong> Agents confidently assert false safety facts.</li>
                                    <li><strong>Drift:</strong> Defaults to generic morality rather than domain-specific rules.</li>
                                </ul>
                            </div>
                            <div class="threat-level">
                                <span class="badge bg-danger">Epistemological Risk</span>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="col-lg-4 mb-4">
                    <div class="semsi-category" data-category="policy">
                        <div class="category-header" onclick="toggleCategory('policy', event)">
                            <h4 class="icon-hazard">Policy-Following Frameworks</h4>
                            <span class="toggle-icon">+</span>
                        </div>
                        <div class="category-content" id="policy-content">
                            <p><strong>Definition:</strong> Systems allowing inference-time policy input (e.g., GPT-OSS-Safeguard).</p>
                            <div class="examples">
                                <h6>Limitations:</h6>
                                <ul>
                                    <li>Architectural coupling to specific model weights.</li>
                                    <li>Relies on single-pass reasoning without dialectical validation.</li>
                                    <li>Restricts leveraging newer, more capable models as judges.</li>
                                </ul>
                            </div>
                            <div class="threat-level">
                                <span class="badge bg-danger">Lock-in Risk</span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="framework" class="py-5 bg-light">
        <div class="container">
            <h2 class="section-title">The CourtGuard Framework</h2>

            <div class="row mb-5">
                <div class="col-lg-10 mx-auto">
                    <div class="method-figure-container">
                        <div class="figure-title text-center mb-3">
                            <h5>Schematic overview of the CourtGuard methodology</h5>
                            <p class="figure-caption text-muted">A three-stage pipeline transforming safety evaluation into Evidentiary Debate.</p>
                        </div>
                        <div class="method-figure-image text-center">
                            <img src="main_system.png" alt="CourtGuard Framework Diagram showing Policy Grounding RAG, Adversarial Debate Module, and Judge Evaluation" class="img-fluid framework-image clickable-image" onclick="openImageModal(this)">
                        </div>
                    </div>
                </div>
            </div>

            <div class="row">
                <div class="col-lg-10 mx-auto">
                    <div class="framework-explanation">
                        <h4>Tri-Component Architecture</h4>
                        <p>CourtGuard addresses the limitations of "black-box" guardrails through a transparent, decoupled pipeline:</p>

                        <div class="agent-details row">
                            <div class="col-md-4">
                                <div class="agent-card eval-card h-100 p-3 border rounded bg-white">
                                    <h5><i class="icon-eval"></i> 1. Policy Grounding RAG</h5>
                                    <p>Given a corpus of governance documents (e.g., MLCommons, OpenAI Usage Policies), it segments, embeds, and retrieves the top-k most relevant clauses to ground all subsequent debate rounds. Replaces implicit intuition with facts.</p>
                                </div>
                            </div>

                            <div class="col-md-4">
                                <div class="agent-card edit-card h-100 p-3 border rounded bg-white">
                                    <h5><i class="icon-edit"></i> 2. Adversarial Debate</h5>
                                    <p>A structured N-round debate (default N=2). <br><strong>Attacker (A):</strong> Identifies regulatory and practical pathways to harm. <br><strong>Defender (D):</strong> Counters with evidence of compliance, exemptions, and high implementation barriers.</p>
                                </div>
                            </div>

                            <div class="col-md-4">
                                <div class="agent-card eval-card h-100 p-3 border rounded bg-white">
                                    <h5><i class="icon-eval"></i> 3. Judge Evaluation</h5>
                                    <p>The Judge synthesizes the debate, assigning threat scores (1-3) for Regulatory and Practical threats. The total rating determines the deterministic final verdict: {SAFE, BORDERLINE, UNSAFE}.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="results" class="py-5">
        <div class="container">
            <h2 class="section-title">Benchmark Results</h2>
    
            <!-- Main Results Table -->
            <div class="results-table-container mb-5">
                <h4 class="mb-3">Table 1: Main Results — Accuracy / F1 Across 8 Datasets</h4>
                <p class="text-muted mb-4">
                    CourtGuard-GPT-OSS-20B (2 Iter) achieves the highest macro average accuracy (0.87) and F1 (0.86), 
                    surpassing dedicated fine-tuned guardrails like LlamaGuard 4 and WildGuard without any fine-tuning. 
                    <strong>Bold</strong> = best. <span class="text-decoration-underline">Underline</span> = second best.
                </p>
                <div class="table-responsive">
                    <table class="table table-bordered table-hover complex-table">
                        <thead class="table-dark">
                            <tr>
                                <th rowspan="2">Method</th>
                                <th colspan="2">AVG</th>
                                <th colspan="2">AdvBenchM</th>
                                <th colspan="2">JailJudge</th>
                                <th colspan="2">WildGuard</th>
                                <th colspan="2">HarmBench</th>
                                <th colspan="2">SafeRLHF</th>
                                <th colspan="2">BeaverTails</th>
                                <th colspan="2">XSTest</th>
                                <th colspan="2">ToxicChat</th>
                            </tr>
                            <tr class="table-secondary">
                                <th>Acc</th><th>F1</th>
                                <th>Acc</th><th>F1</th>
                                <th>Acc</th><th>F1</th>
                                <th>Acc</th><th>F1</th>
                                <th>Acc</th><th>F1</th>
                                <th>Acc</th><th>F1</th>
                                <th>Acc</th><th>F1</th>
                                <th>Acc</th><th>F1</th>
                                <th>Acc</th><th>F1</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr class="table-light">
                                <td colspan="19"><strong>Static Guardrails & Baselines</strong></td>
                            </tr>
                            <tr>
                                <td>LlamaGuard 4</td>
                                <td>0.77</td><td>0.75</td>
                                <td>0.96</td><td>0.98</td>
                                <td>0.72</td><td>0.74</td>
                                <td>0.76</td><td>0.66</td>
                                <td>0.78</td><td>0.81</td>
                                <td>0.84</td><td>0.85</td>
                                <td>0.50</td><td>0.64</td>
                                <td>0.94</td><td>0.83</td>
                                <td>0.69</td><td>0.49</td>
                            </tr>
                            <tr>
                                <td>LlamaGuard 3</td>
                                <td>0.75</td><td>0.70</td>
                                <td>0.98</td><td>0.99</td>
                                <td>0.66</td><td>0.71</td>
                                <td>0.80</td><td>0.67</td>
                                <td>0.73</td><td>0.77</td>
                                <td>0.87</td><td>0.88</td>
                                <td>0.53</td><td>0.68</td>
                                <td>0.82</td><td>0.61</td>
                                <td>0.61</td><td>0.30</td>
                            </tr>
                            <tr>
                                <td>ShieldGemma 2B</td>
                                <td>0.58</td><td>0.42</td>
                                <td>0.34</td><td>0.51</td>
                                <td>0.52</td><td>0.35</td>
                                <td>0.66</td><td>0.29</td>
                                <td>0.55</td><td>0.44</td>
                                <td>0.64</td><td>0.54</td>
                                <td>0.43</td><td>0.56</td>
                                <td>0.84</td><td>0.62</td>
                                <td>0.64</td><td>0.04</td>
                            </tr>
                            <tr>
                                <td>ShieldGemma 9B</td>
                                <td>0.45</td><td>0.15</td>
                                <td>0.00</td><td>0.00</td>
                                <td>0.44</td><td>0.23</td>
                                <td>0.62</td><td>0.11</td>
                                <td>0.43</td><td>0.05</td>
                                <td>0.47</td><td>0.19</td>
                                <td>0.18</td><td>0.23</td>
                                <td>0.76</td><td>0.15</td>
                                <td>0.67</td><td>0.24</td>
                            </tr>
                            <tr>
                                <td>ShieldGemma 27B</td>
                                <td>0.57</td><td>0.53</td>
                                <td>0.46</td><td>0.63</td>
                                <td>0.50</td><td>0.54</td>
                                <td>0.60</td><td>0.45</td>
                                <td>0.48</td><td>0.47</td>
                                <td>0.67</td><td>0.64</td>
                                <td>0.53</td><td>0.67</td>
                                <td>0.74</td><td>0.52</td>
                                <td>0.57</td><td>0.31</td>
                            </tr>
                            <tr>
                                <td>WildGuard</td>
                                <td>0.86</td><td>0.84</td>
                                <td>1.00</td><td>1.00</td>
                                <td>0.88</td><td>0.89</td>
                                <td>0.87</td><td>0.82</td>
                                <td>0.84</td><td>0.86</td>
                                <td>0.84</td><td>0.88</td>
                                <td>0.80</td><td>0.88</td>
                                <td>0.97</td><td>0.90</td>
                                <td>0.66</td><td>0.53</td>
                            </tr>
                            <tr>
                                <td>JailJudge-Finetuned</td>
                                <td>0.84</td><td>0.81</td>
                                <td>0.96</td><td>0.98</td>
                                <td>0.92</td><td>0.92</td>
                                <td>0.85</td><td>0.75</td>
                                <td>0.83</td><td>0.84</td>
                                <td>0.88</td><td>0.90</td>
                                <td>0.67</td><td>0.78</td>
                                <td>0.96</td><td>0.89</td>
                                <td>0.64</td><td>0.40</td>
                            </tr>
                            <tr>
                                <td>GPT-OSS-Safeguard-20B</td>
                                <td>0.82</td><td>0.78</td>
                                <td>0.98</td><td>0.99</td>
                                <td>0.80</td><td>0.78</td>
                                <td>0.88</td><td>0.80</td>
                                <td>0.82</td><td>0.82</td>
                                <td>0.87</td><td>0.88</td>
                                <td>0.57</td><td>0.70</td>
                                <td>0.98</td><td>0.93</td>
                                <td>0.66</td><td>0.32</td>
                            </tr>
                            <tr class="table-light">
                                <td colspan="19"><strong>Generic LLM Judges</strong></td>
                            </tr>
                            <tr>
                                <td>Ordinary Judge (Llama-70B)</td>
                                <td>0.63</td><td>0.43</td>
                                <td>0.96</td><td>0.98</td>
                                <td>0.46</td><td>0.13</td>
                                <td>0.76</td><td>0.51</td>
                                <td>0.55</td><td>0.36</td>
                                <td>0.66</td><td>0.58</td>
                                <td>0.19</td><td>0.24</td>
                                <td>0.84</td><td>0.33</td>
                                <td>0.65</td><td>0.32</td>
                            </tr>
                            <tr>
                                <td>Ordinary Judge (GPT-OSS-20B)</td>
                                <td>0.83</td><td>0.81</td>
                                <td>0.86</td><td>0.92</td>
                                <td>0.86</td><td>0.85</td>
                                <td>0.88</td><td>0.81</td>
                                <td>0.78</td><td>0.80</td>
                                <td>0.90</td><td>0.91</td>
                                <td>0.66</td><td>0.78</td>
                                <td>0.98</td><td>0.93</td>
                                <td>0.69</td><td>0.48</td>
                            </tr>
                            <tr>
                                <td>Reasoning Llama-70B</td>
                                <td>0.86</td><td>0.84</td>
                                <td>0.94</td><td>0.97</td>
                                <td>0.89</td><td>0.89</td>
                                <td>0.87</td><td>0.79</td>
                                <td>0.87</td><td>0.88</td>
                                <td>0.88</td><td>0.90</td>
                                <td>0.72</td><td>0.82</td>
                                <td>0.96</td><td>0.88</td>
                                <td>0.71</td><td>0.55</td>
                            </tr>
                            <tr>
                                <td>Reasoning GPT-OSS-20B</td>
                                <td>0.85</td><td>0.82</td>
                                <td>0.96</td><td>0.98</td>
                                <td>0.89</td><td>0.89</td>
                                <td>0.88</td><td>0.83</td>
                                <td>0.88</td><td>0.89</td>
                                <td>0.90</td><td>0.92</td>
                                <td>0.72</td><td>0.83</td>
                                <td>0.91</td><td>0.76</td>
                                <td>0.63</td><td>0.45</td>
                            </tr>
                            <tr>
                                <td>Multi-Agent Voting Llama-70B</td>
                                <td>0.86</td><td>0.84</td>
                                <td>0.92</td><td>0.96</td>
                                <td>0.88</td><td>0.88</td>
                                <td>0.87</td><td>0.78</td>
                                <td>0.86</td><td>0.87</td>
                                <td>0.93</td><td>0.94</td>
                                <td>0.71</td><td>0.82</td>
                                <td>0.97</td><td>0.91</td>
                                <td>0.74</td><td>0.57</td>
                            </tr>
                            <tr>
                                <td>Multi-Agent Voting GPT-OSS-20B</td>
                                <td>0.86</td><td>0.83</td>
                                <td>1.00</td><td>1.00</td>
                                <td>0.92</td><td>0.92</td>
                                <td>0.87</td><td>0.83</td>
                                <td>0.86</td><td>0.88</td>
                                <td>0.89</td><td>0.91</td>
                                <td>0.76</td><td>0.85</td>
                                <td>0.89</td><td>0.74</td>
                                <td>0.66</td><td>0.50</td>
                            </tr>
                            <tr>
                                <td>JailJudge-MultiAgent-Llama-70B</td>
                                <td>0.81</td><td>0.78</td>
                                <td>0.74</td><td>0.85</td>
                                <td>0.88</td><td>0.87</td>
                                <td>0.76</td><td>0.56</td>
                                <td>0.83</td><td>0.84</td>
                                <td>0.92</td><td>0.93</td>
                                <td>0.68</td><td>0.79</td>
                                <td>0.98</td><td>0.93</td>
                                <td>0.72</td><td>0.50</td>
                            </tr>
                            <tr>
                                <td>JailJudge-MultiAgent-GPT-OSS-20B</td>
                                <td>0.86</td><td>0.83</td>
                                <td>0.96</td><td>0.98</td>
                                <td>0.90</td><td>0.90</td>
                                <td>0.89</td><td>0.84</td>
                                <td>0.86</td><td>0.87</td>
                                <td>0.89</td><td>0.91</td>
                                <td>0.72</td><td>0.82</td>
                                <td>0.94</td><td>0.84</td>
                                <td>0.70</td><td>0.49</td>
                            </tr>
                            <tr class="table-light">
                                <td colspan="19"><strong>Policy-Grounded (Ours)</strong></td>
                            </tr>
                            <tr>
                                <td>CourtGuard-Llama-70B (1 Iter)</td>
                                <td>0.85</td><td>0.82</td>
                                <td>0.98</td><td>0.99</td>
                                <td>0.86</td><td>0.84</td>
                                <td>0.87</td><td>0.77</td>
                                <td>0.83</td><td>0.83</td>
                                <td>0.92</td><td>0.92</td>
                                <td>0.59</td><td>0.72</td>
                                <td>0.98</td><td>0.93</td>
                                <td>0.76</td><td>0.56</td>
                            </tr>
                            <tr>
                                <td>CourtGuard-Llama-70B (2 Iter)</td>
                                <td>0.86</td><td>0.84</td>
                                <td>1.00</td><td>1.00</td>
                                <td>0.87</td><td>0.86</td>
                                <td>0.88</td><td>0.80</td>
                                <td>0.86</td><td>0.86</td>
                                <td>0.91</td><td>0.92</td>
                                <td>0.63</td><td>0.76</td>
                                <td>0.98</td><td>0.95</td>
                                <td>0.77</td><td>0.58</td>
                            </tr>
                            <tr>
                                <td>CourtGuard-GPT-OSS-20B (1 Iter)</td>
                                <td>0.86</td><td>0.84</td>
                                <td>1.00</td><td>1.00</td>
                                <td>0.89</td><td>0.89</td>
                                <td>0.90</td><td>0.85</td>
                                <td>0.85</td><td>0.87</td>
                                <td>0.89</td><td>0.91</td>
                                <td>0.69</td><td>0.80</td>
                                <td>0.94</td><td>0.84</td>
                                <td>0.72</td><td>0.55</td>
                            </tr>
                            <tr class="table-success">
                                <td>CourtGuard-GPT-OSS-20B (2 Iter) ★</td>
                                <td><strong>0.87</strong></td><td><strong>0.86</strong></td>
                                <td><strong>1.00</strong></td><td><strong>1.00</strong></td>
                                <td>0.89</td><td>0.89</td>
                                <td>0.88</td><td>0.83</td>
                                <td>0.85</td><td>0.87</td>
                                <td>0.89</td><td>0.91</td>
                                <td><strong>0.75</strong></td><td><strong>0.85</strong></td>
                                <td>0.97</td><td>0.92</td>
                                <td><strong>0.72</strong></td><td><strong>0.58</strong></td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
    
            <!-- Human Verified Attacks Table -->
            <div class="results-table-container mb-5">
                <h4 class="mb-3">Table 2: Human-Verified Attack Suite — Aggregated Metrics</h4>
                <p class="text-muted mb-4">
                    Evaluated against 9 adversarial attack styles annotated by 3 human raters (Fleiss' κ = 0.786).
                    CourtGuard-GPT-OSS-20B (1 Iter) achieves the highest Recall (0.957), F2 (0.935), and ROC AUC (0.924).
                </p>
                <div class="table-responsive">
                    <table class="table table-bordered table-hover complex-table">
                        <thead class="table-dark">
                            <tr>
                                <th>Method</th>
                                <th>Acc</th>
                                <th>Prec</th>
                                <th>Rec</th>
                                <th>Spec</th>
                                <th>F1</th>
                                <th>F2</th>
                                <th>ROC AUC</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr class="table-light">
                                <td colspan="8"><strong>Static Guardrails</strong></td>
                            </tr>
                            <tr>
                                <td>LlamaGuard 4</td>
                                <td>0.815</td><td>0.764</td><td>0.788</td><td>0.834</td><td>0.776</td><td>0.783</td><td>0.811</td>
                            </tr>
                            <tr>
                                <td>LlamaGuard 3</td>
                                <td>0.641</td><td>0.548</td><td>0.664</td><td>0.626</td><td>0.600</td><td>0.637</td><td>0.645</td>
                            </tr>
                            <tr>
                                <td>WildGuard</td>
                                <td>0.885</td><td>0.806</td><td>0.942</td><td>0.846</td><td>0.869</td><td>0.911</td><td>0.894</td>
                            </tr>
                            <tr>
                                <td>JailJudge-Finetuned</td>
                                <td>0.887</td><td>0.906</td><td>0.806</td><td>0.943</td><td>0.853</td><td>0.824</td><td>0.874</td>
                            </tr>
                            <tr>
                                <td>GPT-OSS-Safeguard-20B</td>
                                <td>0.919</td><td>0.899</td><td>0.901</td><td>0.931</td><td>0.900</td><td>0.901</td><td>0.916</td>
                            </tr>
                            <tr class="table-light">
                                <td colspan="8"><strong>Generic LLM Judges</strong></td>
                            </tr>
                            <tr>
                                <td>Reasoning Llama-70B</td>
                                <td>0.769</td><td>0.706</td><td>0.739</td><td>0.790</td><td>0.722</td><td>0.732</td><td>0.765</td>
                            </tr>
                            <tr>
                                <td>Reasoning GPT-OSS-20B</td>
                                <td>0.788</td><td>0.719</td><td>0.786</td><td>0.790</td><td>0.751</td><td>0.771</td><td>0.788</td>
                            </tr>
                            <tr>
                                <td>JailJudge-MultiAgent-GPT-OSS-20B</td>
                                <td>0.919</td><td>0.894</td><td>0.907</td><td>0.927</td><td>0.901</td><td>0.905</td><td>0.917</td>
                            </tr>
                            <tr class="table-light">
                                <td colspan="8"><strong>Policy-Grounded (Ours)</strong></td>
                            </tr>
                            <tr>
                                <td>CourtGuard-Llama-70B (1 Iter)</td>
                                <td>0.892</td><td>0.899</td><td>0.826</td><td>0.937</td><td>0.861</td><td>0.840</td><td>0.881</td>
                            </tr>
                            <tr>
                                <td>CourtGuard-Llama-70B (2 Iter)</td>
                                <td>0.916</td><td>0.913</td><td>0.878</td><td>0.943</td><td>0.895</td><td>0.885</td><td>0.910</td>
                            </tr>
                            <tr class="table-success">
                                <td>CourtGuard-GPT-OSS-20B (1 Iter) ★</td>
                                <td><strong>0.918</strong></td><td>0.857</td><td><strong>0.957</strong></td><td>0.891</td><td><strong>0.904</strong></td><td><strong>0.935</strong></td><td><strong>0.924</strong></td>
                            </tr>
                            <tr>
                                <td>CourtGuard-GPT-OSS-20B (2 Iter)</td>
                                <td>0.914</td><td>0.851</td><td>0.957</td><td>0.885</td><td>0.900</td><td>0.933</td><td>0.921</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
    
            <!-- Zero Shot Table -->
            <div class="results-table-container mb-5">
                <h4 class="mb-3">Table 3: Zero-Shot Policy Adaptation — Wikipedia Vandalism</h4>
                <p class="text-muted mb-4">
                    CourtGuard matches the dedicated policy-following model and outperforms the base model
                    with <strong>zero fine-tuning</strong>, simply by swapping the reference policy in the RAG store.
                </p>
                <div class="table-responsive">
                    <table class="table table-bordered complex-table" style="max-width: 400px;">
                        <thead class="table-dark">
                            <tr>
                                <th>Model</th>
                                <th>Accuracy</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>GPT-OSS-20B (Base Judge)</td>
                                <td>86%</td>
                            </tr>
                            <tr>
                                <td>GPT-OSS-Safeguard-20B (Policy-Following)</td>
                                <td>90%</td>
                            </tr>
                            <tr class="table-success">
                                <td><strong>CourtGuard (Ours) ★</strong></td>
                                <td><strong>90%</strong></td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
    
            <!-- Aggregation image kept for visual per-attack breakdown -->
            <div class="results-table-container">
                <h4 class="mb-3">Per-Attack Sensitivity — Human-Verified Suite</h4>
                <p class="text-muted mb-3">
                    Granular breakdown across 9 adversarial attack styles. Click to enlarge.
                </p>
                <div class="text-center">
                    <img src="aggregation.png" alt="Aggregated Performance and Human Verified Attacks" 
                         class="img-fluid border rounded shadow-sm clickable-image" 
                         onclick="openImageModal(this)">
                </div>
            </div>
    
        </div>
    </section>

    <section id="findings" class="py-5 bg-light">
        <div class="container">
            <h2 class="section-title">Key Findings</h2>

            <div class="findings-container">
                <div class="row">
                    <div class="col-lg-6 mb-4">
                        <div class="finding-card h-100" onclick="toggleFinding('pareto', event)">
                            <div class="finding-header">
                                <h4 class="icon-chart">1. Zero-Shot Domain Adaptation</h4>
                                <span class="toggle-icon" id="pareto-toggle">+</span>
                            </div>
                            <div class="finding-content" id="pareto-finding">
                                <p>
                                    CourtGuard successfully generalizes to entirely out-of-domain tasks without any weight updates, simply by swapping the reference policy in the RAG store. 
                                </p>
                                <div class="finding-details">
                                    <h6>Performance Highlights:</h6>
                                    <ul>
                                        <li><strong>Wikipedia Vandalism:</strong> Achieved <strong>90% accuracy</strong> applying WP:VANDAL rules, correctly identifying "silly vandalism" vs "good faith" edits.</li>
                                        <li><strong>Legal & Privacy:</strong> Achieved <strong>93.9% Expert-AI Alignment</strong> when applying complex European Union law (GDPR Art. 5/6 and InfoSoc Directive).</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="col-lg-6 mb-4">
                        <div class="finding-card h-100" onclick="toggleFinding('scale', event)">
                            <div class="finding-header">
                                <h4 class="icon-scale">2. The Liability of Parametric Safety</h4>
                                <span class="toggle-icon" id="scale-toggle">+</span>
                            </div>
                            <div class="finding-content" id="scale-finding">
                                <p>
                                    Baselines relying on "parametric intuition" (implicit knowledge baked into weights) suffer from frozen alignment. They cannot inherently adapt to a new policy without fine-tuning.
                                </p>
                                <div class="finding-details">
                                    <h6>Key Insight:</h6>
                                    <ul>
                                        <li>While generic reasoning models achieve high accuracy, they lack explicit policy grounding.</li>
                                        <li>CourtGuard matches or exceeds SOTA performance while providing <strong>verifiable citations</strong>, eliminating the "black box" trust issue.</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="col-lg-6 mb-4">
                        <div class="finding-card h-100" onclick="toggleFinding('reasoning', event)">
                            <div class="finding-header">
                                <h4 class="icon-reasoning">3. Automated Data Curation & Auditing</h4>
                                <span class="toggle-icon" id="reasoning-toggle">+</span>
                            </div>
                            <div class="finding-content" id="reasoning-finding">
                                <p>
                                    CourtGuard acts as a rigorous policy auditor. In analyzing disagreements with human-annotated ground truth, our model correctly flagged content that human labelers missed.
                                </p>
                                <div class="finding-details">
                                    <h6>Audit Results:</h6>
                                    <ul>
                                        <li>Uncovered significant label noise: <strong>14.67% flip rate</strong> in BeaverTails and <strong>14.44% flip rate</strong> in ToxicChat.</li>
                                        <li>Successfully corrected False Negatives (overlooked masked risks) and False Positives (keyword-triggered over-censorship).</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <div class="col-lg-6 mb-4">
                        <div class="finding-card highlight-finding h-100" onclick="toggleFinding('calibration', event)">
                            <div class="finding-header">
                                <h4 class="icon-calibration">4. Architectural Freedom</h4>
                                <span class="toggle-icon" id="calibration-toggle">+</span>
                            </div>
                            <div class="finding-content" id="calibration-finding">
                                <p>
                                    Unlike bespoke inference-time safeguards (e.g., gpt-oss-safeguard) which are tied to specific weights, CourtGuard strictly decouples safety logic from model weights.
                                </p>
                                <div class="finding-details">
                                    <h6>System Advantages:</h6>
                                    <ul>
                                        <li><strong>No Vendor Lock-in:</strong> Functions identically across Llama-3-70B and GPT-OSS-20B backbones.</li>
                                        <li><strong>Modular Composition:</strong> Allows organizations to deploy lightweight models for defense and heavy models for judgment to optimize costs.</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <footer class="py-4 bg-dark text-light">
        <div class="container">
            <div class="row">
                <div class="col-lg-8">
                    <h5>CourtGuard: A Model-Agnostic Framework for Zero-Shot Policy Adaptation in LLM Safety</h5>
                    <p class="mb-2">
                        An inference-time framework for agentic, policy-grounded adjudication of generative AI responses.
                    </p>
                    <p class="text-muted mb-0">
                        Under review.
                    </p>
                </div>
                <div class="col-lg-4 text-lg-end">
                    <p class="mb-1">Research Areas:</p>
                    <div class="research-tags">
                        <span class="badge bg-secondary">AI Safety</span>
                        <span class="badge bg-secondary">Multi-Agent Systems</span>
                        <span class="badge bg-secondary">RAG</span>
                        <span class="badge bg-secondary">Policy Adaptation</span>
                        <span class="badge bg-secondary">Governance</span>
                    </div>
                </div>
            </div>
        </div>
    </footer>

    <div id="imageModal" class="image-modal" onclick="closeImageModal()">
        <div class="image-modal-content">
            <span class="image-modal-close" onclick="closeImageModal()">&times;</span>
            <img id="modalImage" class="modal-image" src="" alt="">
            <div class="image-modal-caption">
                <h5 id="modalTitle"></h5>
                <p id="modalCaption"></p>
            </div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script>
        // Simple script to handle toggles and modals mimicking original style
        function toggleCategory(categoryId, event) {
            const content = document.getElementById(categoryId + '-content');
            const icon = event.currentTarget.querySelector('.toggle-icon');
            if (content.style.display === "block") {
                content.style.display = "none";
                icon.textContent = "+";
            } else {
                content.style.display = "block";
                icon.textContent = "-";
            }
        }

        function toggleFinding(findingId, event) {
            // Prevent toggling if clicking inside the content itself
            if(event.target.closest('.finding-content')) return;
            
            const content = document.getElementById(findingId + '-finding');
            const icon = document.getElementById(findingId + '-toggle');
            if (content.style.display === "block") {
                content.style.display = "none";
                icon.textContent = "+";
            } else {
                content.style.display = "block";
                icon.textContent = "-";
            }
        }

        function openImageModal(imgElement) {
            const modal = document.getElementById('imageModal');
            const modalImg = document.getElementById('modalImage');
            modal.style.display = "block";
            modalImg.src = imgElement.src;
        }

        function closeImageModal() {
            document.getElementById('imageModal').style.display = "none";
        }
    </script>
</body>
</html>
